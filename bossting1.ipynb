{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e013867-4990-45d8-aaf2-edd54cdf1944",
   "metadata": {},
   "source": [
    "Q1. What is boosting in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e976a4-78ec-43a0-a44d-b13300adbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-  It is a ensemble learning technique.\n",
    "          we build the tree sequentially connected.we combined multiple weak learner into strong learner.\n",
    "             weak learner---->haven not learnt much from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603b84d-581e-4f2d-9099-86bac298c632",
   "metadata": {},
   "source": [
    "Q2. What are the advantages and limitations of using boosting techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0741f-2205-4b52-afc4-b42b57d79e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- \n",
    "      Advantages of using boosting techniques:\n",
    "        i.improved predictive performance\n",
    "         ii.reduce bias & variance\n",
    "            iii.ability to handle imbalance data.\n",
    "            \n",
    "        Limitation of using boosting techniques:\n",
    "            i.potential for overfitting\n",
    "             ii.longer training time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6156cc9f-6fde-4ad9-a2f7-a592af07fa9a",
   "metadata": {},
   "source": [
    "Q3. Explain how boosting works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90383638-f1f1-4047-9014-c9d5faa4ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:- It is a ensemble learning technique.\n",
    "        we build the tree sequentially connected.we combined multiple weak learner into strong learner.\n",
    "    \n",
    "     i.initialize\n",
    "        ii.interactive training\n",
    "          iii.final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a8eee-2b9d-4926-a314-684dadc17252",
   "metadata": {},
   "source": [
    "Q4. What are the different types of boosting algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd55b8-187b-4889-be29-9dd93c775c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-\n",
    "     i.Adaboost------->(Adaptive boosting)\n",
    "       ii.Gradient boosting\n",
    "         iii.XGBoost---->(X-tream gradient boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45508388-6901-4af6-8bae-5df344810015",
   "metadata": {},
   "source": [
    "Q5. What are some common parameters in boosting algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e33cb1-85d4-4973-9e8c-90f9c2c43562",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-\n",
    "      i.iteration\n",
    "        ii.learning rate\n",
    "          iii.max.depth\n",
    "             iv.regularization parameter\n",
    "                v.loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470851a-1eb9-4412-9497-e1e66d4f45eb",
   "metadata": {},
   "source": [
    "Q6. How do boosting algorithms combine weak learners to create a strong learner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76a5d1-80bc-49dc-99c4-8ef6fb5ca17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-we build the tree sequentially.we combined multiple weak learner into strong learner.\n",
    "     dataset----->dt1--->dt2---->dt3---->dtn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a534cd-b695-42a3-a940-ba55fcb312f3",
   "metadata": {},
   "source": [
    "Q7. Explain the concept of AdaBoost algorithm and its working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3d1da-cb5e-4e2c-ac7b-b5f75af9e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-Adaboost is the boosting technique.\n",
    "\n",
    "   Step of adaboost algorithm:-\n",
    "       i. we create decission tree stump & we select the best stump.\n",
    "        ii.we assign sample weight to everyone\n",
    "          iii.sum of total error & performance of stump\n",
    "             iv.update the weights\n",
    "                v.normalize weights computation & assign bins\n",
    "                  vi.select data point to the next stump\n",
    "                    vii.final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b698ac9-2a44-4a05-b6fd-2b6a893f7c98",
   "metadata": {},
   "source": [
    "Q8. What is the loss function used in AdaBoost algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ebef4-3cd7-44a5-a989-9f35d71f2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-AdaBoost used exponential loss function it is default for binary classification problem. \n",
    "      AdaBoost aims to minimize the weighted exponential loss function by adjusting the weights \n",
    "         and contribution of each weak learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f30cb0-8724-4955-a12d-431673db2e2f",
   "metadata": {},
   "source": [
    "Q9. How does the AdaBoost algorithm update the weights of misclassified samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d07ad-1ebf-4f43-9a5a-fb91146a1eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-\n",
    "     i.initialize\n",
    "      ii.weak learner training\n",
    "        iii.error calculation\n",
    "          iv.weight update------->increased weight----->normalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75e3e3-5286-45c4-90bb-5eded2b2a530",
   "metadata": {},
   "source": [
    "Q10. What is the effect of increasing the number of estimators in AdaBoost algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e64155-0226-405b-bffe-8355bc80f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans:-\n",
    "     i.improved overall performance\n",
    "      ii.increased model complexity\n",
    "        iii.reduced bias\n",
    "           iv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
